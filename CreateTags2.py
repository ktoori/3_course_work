import spacy
from collections import defaultdict

# Загружаем модель spaCy для русского языка
nlp = spacy.load('ru_core_news_sm')


def extract_candidate_keyphrases(doc):
    """
    Извлекает кандидатов в ключевые фразы из документа.
    Вместо doc.noun_chunks, который не реализован для 'ru', группируем токены,
    если их часть речи – ADJ, NOUN или PROPN.
    """
    candidates = []
    candidate_tokens = []

    for token in doc:
        # Если токен имеет нужный тип, добавляем его в текущую группу
        if token.pos_ in ("ADJ", "NOUN", "PROPN"):
            candidate_tokens.append(token.text.lower())
        else:
            # Если группа не пуста, объединяем в фразу и сбрасываем список
            if candidate_tokens:
                candidate_phrase = " ".join(candidate_tokens)
                candidates.append(candidate_phrase)
                candidate_tokens = []
    # Обработка оставшихся токенов после цикла
    if candidate_tokens:
        candidate_phrase = " ".join(candidate_tokens)
        candidates.append(candidate_phrase)

    return candidates


def compute_candidate_features(candidates, doc):
    """
    Для каждого кандидата вычисляются признаки:
    - Частотность появления (freq)
    - Позиция первого появления (first_occurrence)

    Итоговый балл: score = frequency * (1 - (first_occurrence / total_tokens))
    """
    total_tokens = len(doc)
    features = defaultdict(lambda: {"freq": 0, "first_occurrence": total_tokens})

    # Для каждого кандидата ищем его первое появление в документе по токенам
    for candidate in candidates:
        # Увеличиваем счётчик частотности
        features[candidate]["freq"] += 1

    # Определяем позицию первого вхождения для каждого кандидата
    for candidate in features:
        candidate_tokens = candidate.split()
        first_index = total_tokens  # инициализируем большим числом
        # Пробегаем по токенам документа и ищем совпадение по последовательности
        for i in range(total_tokens - len(candidate_tokens) + 1):
            window = [doc[j].text.lower() for j in range(i, i + len(candidate_tokens))]
            if window == candidate_tokens:
                first_index = i
                break
        features[candidate]["first_occurrence"] = first_index

    # Вычисляем итоговый балл
    for candidate, feat in features.items():
        pos_factor = 1 - (feat["first_occurrence"] / total_tokens)
        feat["score"] = feat["freq"] * pos_factor

    return features


if __name__ == "__main__":
    # Пример текста на русском языке
    text = (
        "Правила приема в Национальный исследовательский университет «Высшая школа экономики» для поступающих на обучение по образовательным программам высшего образования – программам бакалавриата, программам специалитета"
        "1. Общие положения 1.1. Правила приема в Национальный исследовательский университет «Высшая школа экономики» для поступающих на обучение по образовательным программам высшего образования – программам бакалавриата, программам специалитета (далее"
        "соответственно – Правила, НИУ ВШЭ, программы бакалавриата, программы специалитета) разработаны в соответствии с Федеральным законом от 29.12.2012 № 273-ФЗ «Об образовании в Российской Федерации» (далее – Закон № 273-ФЗ), Порядком приема на обучение по образовательным программам высшего образования – программам бакалавриата, программам специалитета, программам магистратуры, утвержденным приказом Минобрнауки России от 27.11.2024 № 821 (далее – Порядок № 821), Перечнем вступительных испытаний при приеме на обучение по образовательным программам высшего образования – программам бакалавриата и программам специалитета, утвержденным приказом Минобрнауки России от"
        "27.11.2024 № 820, постановлением Правительства Российской Федерации от 27.04.2024 № 555 «О целевом обучении по образовательным программам среднего профессионального и высшего образования» (далее – постановление Правительства Российской Федерации от 27.04.2024 № 555). 1.2. Правила регламентируют прием граждан Российской Федерации, иностранных граждан и лиц без гражданства (далее вместе – поступающие, абитуриенты) на обучение по очной форме обучения, очно-заочной форме обучения по программам бакалавриата, программам специалитета в НИУ ВШЭ и его филиалы. 1.3. НИУ ВШЭ проводит отдельный конкурс для поступления на обучение в"
        "НИУ ВШЭ и в каждом из филиалов НИУ ВШЭ. 1.4. Прием на обучение осуществляется на первый курс. 1.5. Организационное обеспечение проведения приема на обучение, в том числе для обучения в филиалах НИУ ВШЭ, осуществляется в соответствии с Положением о приемной комиссии НИУ ВШЭ (далее – Приемная комиссия). 1.6. Официальные электронные адреса взаимодействия с Приемной комиссией: НИУ ВШЭ (г. Москва) – электронный адрес abitur@hse.ru; 2 НИУ ВШЭ – Нижний Новгород – электронный адрес pknn@hse.ru; НИУ ВШЭ – Пермь – электронный адрес abitur.perm@hse.ru; НИУ ВШЭ – Санкт-Петербург – электронный адрес abitur-spb@hse.ru. 1.7. Вопросы, связанные с приемом в НИУ ВШЭ и не урегулированные Правилами, решаются Приемной комиссией в соответствии с законодательством Российской Федерации"
    )

    # Обрабатываем текст с помощью spaCy
    doc = nlp(text)

    # Шаг 1: Извлекаем кандидатов с использованием кастомной функции
    candidates = extract_candidate_keyphrases(doc)

    # Шаг 2: Вычисляем статистические признаки для кандидатов
    candidate_features = compute_candidate_features(candidates, doc)

    # Шаг 3: Сортируем кандидатов по рассчитанному баллу (score)
    sorted_candidates = sorted(candidate_features.items(), key=lambda x: x[1]["score"], reverse=True)

    print("Извлечённые ключевые фразы (упрощённый KEA):")
    for candidate, feat in sorted_candidates:
        print(
            f"{candidate}: score={feat['score']:.4f}, freq={feat['freq']}, first_occurrence={feat['first_occurrence']}")